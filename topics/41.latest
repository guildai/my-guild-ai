<div data-theme-toc="true"> </div>

## Overview

In the [previous section](/start), you use Guild to run `train.py` --- a sample training script. In this section, you run the same script with different hyperparameter values to find lower values of `loss`. This process is known as [hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization), or hyperparameter *tuning*.

Guild supports hyperparameter optimization using different search methods:

- Manual search
- [Grid Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search)
- [Random search](https://en.wikipedia.org/wiki/Random_search)
- [Bayesian optimization](https://en.wikipedia.org/wiki/Bayesian_optimization)

For review, here's the loss function used in `train.py`:

``` python
loss = (np.sin(5 * x) * (1 - np.tanh(x ** 2)) + np.random.randn() * noise)
```

The relationship between `x` and `loss` is plotted below. Optimal values for `x` are around -0.3.

![bayesian-optimization|383x252](upload://eBqWfSoU4FFBIsSDiCcgEUbnNvH.png)

&nbsp; *Plot of `x` on the horizontal axis to `loss` on the vertical axis ([image credit](https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html))*

In a real scenario, we don't know the optimal hyperparameter values --- we need to search for them.

## Manual Search

When experimenting with hyperparameters, it's useful to start with values based on prior experience or intuition.

Guild lets you run multiple trials in a batch by specifying them as a list in the form ``[VAL1,VAL2,...,VALN]``.

Run three trials of `train.py` using different values for `x`:

``` command
guild run train.py x=[-1,0,1]
```

``` output
You are about to run train.py as a batch (3 trials)
  noise: 0.1
  x: [-1, 0, 1]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Guild runs `train.py` three times, once for each specified value of `x`.

Show the runs:

``` command
guild runs
```

``` output
[1:1933bdcb]  train.py   2020-01-14 09:38:15  completed  noise=0.1 x=1
[2:83dc048d]  train.py   2020-01-14 09:38:14  completed  noise=0.1 x=0
[3:468bb240]  train.py   2020-01-14 09:38:14  completed  noise=0.1 x=-1
[4:bfcff413]  train.py+  2020-01-14 09:38:13  completed
[5:68f4da74]  train.py   2020-01-14 08:42:54  completed  noise=0.1 x=0.1
```

Runs 1 through 3 are the *trial runs* generated by the command. Run 4 is a [batch run](/runs#batches). Batch runs are responsible for generating trials and are denoted using ``+`` in their name.

### Compare Runs

To compare `loss` across runs, use the [compare](/commands/compare) command:

``` command
guild compare --min loss
```

Guild starts an interactive application that lets you browse experiment results. Runs with lower `loss` appear at the top due to ``--min loss``. Use arrow keys to navigate. Press `1` to sort by the current column in ascending order or `2` to sort in descending order. Press `?` for a list of supported commands.

![compare-start|690x94, 100%](upload://zB2Ne8Zp1UYz5Ymu3EqiubUlMu9.png)

&nbsp; *Compare experiment results --- press `?` for a list of commands, `q` to exit*

Exit *Guild Compare* by pressing `q`.

Next, run four trials --- one for for each unique combination of the specified flag values:

``` command
guild run train.py x=[-0.5,0.5] noise=[0.1,0.2]
```

``` output
You are about to run train.py as a batch (4 trials)
  noise: [0.1, 0.2]
  x: [-0.5, 0.5]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Show the top-3 best runs:

``` command
guild compare --table --min loss --top 3
```

The `--table` option tells Guild to show results without running in interactive mode. The `--top` option tells Guild to show only the top-*N* runs based on the sort order.

Note that runs where `x` is `-0.5` have the lowest `loss`. This is consistent with our expectation from the plot above.

### View Runs in TensorBoard

View runs in [TensorBoard](https://www.tensorflow.org/tensorboard) using the [`tensorboard`](/commands/tensorboard) command:

``` command
guild tensorboard
```

Guild starts TensorBoard and opens a new tab in your browser. Use TensorBoard to view run results, including scalars, images, embeddings, and hyperparameters.

Select the **HParams** tab and then select **Parallel Coordinates View**.

![tb-hparams|690x441, 100%](upload://n3OlgNmYi2BNWZSQ4UmrSz1P74G.png)

&nbsp; *Compare runs using Parallel Coordinates View*

The *Parallel Coordinates View* highlights runs that perform better along various axes. Click-and-drag along the `loss` axis to highlight runs with the lowest values. Note that runs where `x` is `-0.5` are highlighted.

> **HIGHLIGHT**
Guild automatically generates *HParam* summaries from Guild runs to simply the process of comparing runs in TensorBoard.

Return to the command terminal and type `Ctrl-C` to stop TensorBoard.

## Grid Search

Grid search is a systematic search across a subset of hyperparameter space. Guild supports a special  [*sequence function*](/flags#sequence-functions) syntax for specifying value ranges. Ranges are specified using the format *`function`*`[`*`start`*`:`*`end`*`:`*`step-or-count`*`]` where *`function`* is the type of sequence and *`start`* and *`end`* mark the start and end of the sequence respectively. *`step-or-count`* is the range step or value count depending on the function used.

Use [`linspace`](/flags#linspace) to run four trials where `x` is evenly spaced between `-0.6` and `0.6`:

``` command
guild run train.py x=linspace[-0.6:0.6:4]
```

``` output
You are about to run train.py as a batch (max 20 trials, minimize loss)
  noise: 0.1
  x: [-0.6, -0.2, 0.2, 0.6]
Continue? (Y/n)
```

Guild expands the function ``linspace[-0.6:0.6:4]`` to the list ``[-0.6, -0.2, 0.2, 0.6]``.

Press `Enter` to start the batch.

Guild runs trials for each value of `x` generated by the `linspace` function.

> **TIP**
Use sequence functions for multiple flags to expand a grid search to the Cartesian product of each set of values.

## Random Search

Guild supports random search over a both uniform and log-uniform distributions.

Search space is specified by special [*search space functions*](/flags#search-space-functions), which include [`uniform`](/flags#uniform) and [`loguniform`](/flags#loguniform). The `uniform` function name may be omitted.

To search over a uniformly distributed range of values, specify a flag value in the format `[`*`min`*`:`*`max`*`]`. By default, Guild runs 20 trials using randomly chosen values within the specified range. Use `--max-trials` to specify a different limit.

Start a random search over `x` with 5 trials:

``` command
guild run train.py x=[-2.0:2.0] --max-trials 5
```

``` output
You are about to run train.py with random search (max 5 trials)
  noise: 0.1
  x: [-2.0:2.0]
Continue? (Y/n)
```

Press `Enter` to start the batch.

Guild runs `train.py` five times using randomly sampled values for `x` from `-2.0` to `2.0`.

## Bayesian Optimization

Bayesian optimization uses light-weight probabilistic models to suggest hyperparameter values believed to improve a future result based on previous results.

By default, Guild attempts to minimize `loss`, which is logged by `train.py`. If the script used a different objective, specify it using `--minimize` or `--maximize` options for the [`run`](/commands/run) command.

Run 10 trials using the [`gp`](/reference/optimizers#gp) optimizer, which uses Bayesian optimization with Gaussian processes:

``` command
guild run train.py x=[-2.0:2.0] --optimizer gp --max-trials 10
```

``` output
You are about to run train.py with 'skopt:gp' optimizer (max 10 trials, minimize loss)
  noise: 0.1
  x: [-2.0:2.0]
Optimizer flags:
  acq-func: gp_hedge
  kappa: 1.96
  noise: gaussian
  random-starts: 3
  xi: 0.05
Continue? (Y/n)
```

Press `Enter` to start the batch.

The `gp` optimizer seeds the batch with three random starts. After the third random start, the optimizer uses previous results to suggest candidates for `x` between `-2.0` and `2.0` to minimize `loss`.

For list of available optimizes, see [Optimizers](/reference/optimizers).

### Restart Batch to Continue Optimization

Guild optimizers use previous results from trials *of the same batch*. If you want to continue a search for hyperparameters using previous results, you must restart the batch run.

To restart a run, you need the target run ID.

To get the run ID of the `gp` batch, run:

``` command
guild select -o train.py+gp
```

Guild prints the ID of the last `gp` batch run. Copy this value for the next command.

Restart the batch to generate another ten trials, replacing ``<batch run ID>`` below with ID from the previous command:

``` command
guild run -Fo random-starts=0 --restart <batch run ID>
```

``` output
You are about to start <batch run ID> (train.py) with 'skopt:gp' optimizer (max 10 trials)
  noise: 0.1
  x: [-2.0:2.0]
Optimizer flags:
  acq-func: gp_hedge
  kappa: 1.96
  noise: gaussian
  random-starts: 0
  xi: 0.05
Continue? (Y/n)
```

> **TIP**
You can type the first few characters of the batch run ID rather than use the full ID, provided the first characters uniquely identify the run.

> **TIP**
If you are running Linux, macOS, or another POSIX environment, you can use [command substitution](https://www.gnu.org/software/bash/manual/html_node/Command-Substitution.html) and the [`select`](/commands/select) command to specify a run ID argument. For example, ``guild run --restart $(guild select -o train.py+gp)`` will replace the argument ``$(...)`` with the run ID returned by `guild select`.

Press `Enter` to restart the batch.

Guild generates another ten trials for the batch. Guild uses the previous trials generated earlier as inputs to the optimization.

The option ``-Fo random-starts=0`` is an [optimizer flag](/runs#optimizer-flags) that sets the number of random starts to `0`.

### Evaluate Bayesian Optimization Results

Run [compare](cmd:compare) on the last 20 runs to evaluate the results of the Bayesian optimization:

``` command
guild compare :20
```

By default, Guild shows runs ordered by start time starting with the latest run first. Note the values for `x` that the `gp` optimizer suggests. If the optimizer is effective in finding values for `x` that minimize `loss`, you see more values around `-0.3` toward the top of the list (i.e. the more recent runs, which benefit from more trial data).

Press `q` to exit Guild Compare.

You can also use TensorBoard to evaluate optimization results.

Start TensorBoard to view the last 20 runs:

``` command
guild tensorboard :20
```

Guild starts TensorBoard and opens a new browser tab.

Select the **HParams** tag and then select **Scatter Plot Matrix View**.

TensorBoard displays scatter plots of hyperparameters and metrics.

In the left side panel, *deselect* the following hyperparameters:

- `noise`
- `sourcecode`

In the same panel, *deselect* the following metrics:

- `time`

TensorBoard displays a plot of `loss` against `x`. Each point on the plot represents a trial. Given the known relationship between `loss` and `x` (see plot above), the Bayesian optimizer should spend more time exploring values for `x` around `-0.3`. This will appear as a cluster of trials along the bottom of the plot between `-0.4` and `-0.2`.

![tb-hparams-scatter|690x409](upload://2yyqhZe8oXNE4SjyRYB1GNy7ZkB.png)

&nbsp; *Plot `loss` against `x` to evaluate the Bayesian optimization results*

Return to the command terminal and type `Ctrl-C` to stop TensorBoard.

## Summary

In this section, you use various techniques to run `train.py`.

> **HIGHLIGHT**
Run experiments using a variety of methods for exploring different hyperparameters including grid search, random search, and Bayesian optimization.

In the [next section](/start/runs), you learn how to manage runs.
